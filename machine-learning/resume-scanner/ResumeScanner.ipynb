{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2bef906b-f0c1-468a-9f81-ecafae53de4c",
   "metadata": {},
   "source": [
    "To design a system that categorizes candidates into three categories (Best Fit, Moderate Fit, and No Fit), we need to perform a few key steps. These will involve extracting relevant information from all three sources (Candidate portal data, Resumes, and Job Descriptions) and then using machine learning models to match candidates to job descriptions.\n",
    "\n",
    "Outline of the Approach:\n",
    "Data Preprocessing:\n",
    "\n",
    "Extract structured data from Source 1 (Candidate Portal) and Source 2 (Resumes).\n",
    "\n",
    "Clean, preprocess, and normalize the data.\n",
    "\n",
    "Feature Extraction:\n",
    "\n",
    "Extract relevant features from resumes (Candidate Name, Experience, Domains worked, Languages, etc.).\n",
    "\n",
    "Convert text data like job descriptions and resumes into numerical vectors (using TF-IDF or embeddings like BERT).\n",
    "\n",
    "Candidate-Job Matching:\n",
    "\n",
    "For each candidate, calculate a similarity score with the job description based on their features and the jobâ€™s description using cosine similarity, word embeddings, or transformers.\n",
    "\n",
    "Clustering the Candidates:\n",
    "\n",
    "Use clustering algorithms like K-Means or hierarchical clustering to categorize candidates into the three categories: Best Fit, Moderate Fit, and No Fit.\n",
    "\n",
    "Model Training:\n",
    "\n",
    "If required, train a classification model (using labeled data, if available) to classify candidates directly into these three categories based on features.\n",
    "\n",
    "Below is a simplified version of the ML pipeline. I'll break down the code into different steps, assuming you're using Python for implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "addd88c6-c347-40a6-b9f7-cec22fe45994",
   "metadata": {},
   "source": [
    "### Step 1: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7957336b-0b1f-4848-8317-9158a2b4aadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Sample Candidate Data (Source 1)\n",
    "df_candidates = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'location_preferences': ['New York', 'San Francisco', 'Austin', 'Seattle', 'Boston'],\n",
    "    'languages_known': ['Python, Java', 'JavaScript, HTML, CSS', 'Python, Java, SQL', 'Java, C++', 'Python, R'],\n",
    "    'experience': [5, 3, 7, 10, 2]\n",
    "})\n",
    "\n",
    "# Sample Resume Data (Source 2)\n",
    "df_resumes = pd.DataFrame({\n",
    "    'candidate_name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'resume_text': [\n",
    "        \"Experienced software engineer with a strong background in Python, Java. Worked on large-scale applications in AI and data analysis.\",\n",
    "        \"Frontend developer with experience in building responsive web applications using JavaScript, HTML, and CSS.\",\n",
    "        \"Senior software engineer with experience in backend development using Python, Java. Strong experience with databases and data processing.\",\n",
    "        \"Lead developer with expertise in Java and C++. Managed a team of engineers in building scalable systems.\",\n",
    "        \"Junior data scientist skilled in Python, R, machine learning, and statistical analysis.\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Sample Job Description Data (Source 3)\n",
    "# df_jobs = pd.DataFrame({\n",
    "#     'position_title': ['Software Engineer', 'Frontend Developer', 'Senior Software Engineer', 'Lead Developer', 'Data Scientist'],\n",
    "#     'description': [\n",
    "#         \"We are looking for a software engineer with experience in Python and Java. Should have a good understanding of algorithms and problem-solving.\",\n",
    "#         \"Frontend developer needed for web application development. Proficiency in JavaScript, HTML, and CSS is required.\",\n",
    "#         \"Senior software engineer required with experience in backend technologies like Python, Java. Knowledge of databases is necessary.\",\n",
    "#         \"Lead developer with experience in Java and C++, experience in managing teams and building scalable systems.\",\n",
    "#         \"Data scientist role for someone skilled in Python, R, machine learning, and statistical analysis. Experience with data manipulation is a plus.\"\n",
    "#     ],\n",
    "#     'experience_required': [4, 2, 6, 8, 3],\n",
    "#     'domain': ['Software Engineering', 'Frontend Development', 'Software Engineering', 'Software Engineering', 'Data Science'],\n",
    "#     'location': ['New York', 'San Francisco', 'Austin', 'Seattle', 'Boston']\n",
    "# })\n",
    "\n",
    "df_jobs = pd.DataFrame({\n",
    "    'position_title': ['Software Engineer'],\n",
    "    'description': [\n",
    "        \"We are looking for a software engineer with experience in Python and Java. Should have a good understanding of algorithms and problem-solving.\"\n",
    "        \n",
    "    ],\n",
    "    'experience_required': [4],\n",
    "    'domain': ['Software Engineering'],\n",
    "    'location': ['New York']\n",
    "})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a097f038-e994-4a7b-8947-77ca6cfcb1cb",
   "metadata": {},
   "source": [
    "### Step 2: Feature Extraction (TF-IDF for Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a2fc26c-2ae7-498f-8996-0753588ed0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Preprocess Candidate Data\n",
    "def preprocess_candidate_data(df):\n",
    "    df['name'] = df['name'].str.lower()\n",
    "    df['location_preferences'] = df['location_preferences'].str.lower()\n",
    "    df['languages_known'] = df['languages_known'].str.lower()\n",
    "    return df\n",
    "\n",
    "# Preprocess Resume Data\n",
    "def preprocess_resume_data(df):\n",
    "    df['resume_text'] = df['resume_text'].str.lower().apply(lambda x: re.sub(r'[^a-z\\s]', '', x))\n",
    "    return df\n",
    "\n",
    "# Preprocess Job Description Data\n",
    "def preprocess_job_description_data(df):\n",
    "    df['description'] = df['description'].str.lower().apply(lambda x: re.sub(r'[^a-z\\s]', '', x))\n",
    "    return df\n",
    "\n",
    "# Apply preprocessing\n",
    "df_candidates = preprocess_candidate_data(df_candidates)\n",
    "df_resumes = preprocess_resume_data(df_resumes)\n",
    "df_jobs = preprocess_job_description_data(df_jobs)\n",
    "\n",
    "# TF-IDF Vectorizer for Resume Text and Job Description Text\n",
    "vectorizer = TfidfVectorizer(stop_words='english', max_features=5000)\n",
    "\n",
    "# Combine candidate's resume text and job descriptions for similarity calculation\n",
    "def compute_tfidf_matrix(resume_texts, job_descriptions):\n",
    "    resume_tfidf = vectorizer.fit_transform(resume_texts)\n",
    "    job_desc_tfidf = vectorizer.transform(job_descriptions)\n",
    "    return resume_tfidf, job_desc_tfidf\n",
    "\n",
    "# Compute the TF-IDF matrix for resumes and job descriptions\n",
    "resume_tfidf, job_desc_tfidf = compute_tfidf_matrix(df_resumes['resume_text'], df_jobs['description'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ecd034-6ad2-4dcb-bbab-fbcb373beaac",
   "metadata": {},
   "source": [
    "### Step 3: Calculate Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e9086fa-a2ee-4312-a8ad-d2595ce5cc37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity Matrix:\n",
      " [[0.42039137]\n",
      " [0.12674805]\n",
      " [0.61010361]\n",
      " [0.08981684]\n",
      " [0.09670659]]\n"
     ]
    }
   ],
   "source": [
    "# Cosine Similarity Calculation between Candidates' Resumes and Job Descriptions\n",
    "def calculate_cosine_similarity(resume_tfidf, job_desc_tfidf):\n",
    "    similarity_matrix = cosine_similarity(resume_tfidf, job_desc_tfidf)\n",
    "    return similarity_matrix\n",
    "\n",
    "similarity_matrix = calculate_cosine_similarity(resume_tfidf, job_desc_tfidf)\n",
    "\n",
    "# Check the similarity matrix\n",
    "print(\"Cosine Similarity Matrix:\\n\", similarity_matrix)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c85e9ba7-4f1a-49f8-a044-b0f33cd60d5a",
   "metadata": {},
   "source": [
    "### Step 4: Candidate Fit Categorization Using Clustering\n",
    "We will use a clustering algorithm like K-Means to categorize candidates into 3 clusters: Best Fit, Moderate Fit, No Fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3c4f7e96-0272-459b-819a-1de751eaef4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidates with Fit Categories:\n",
      "       name location_preferences        languages_known  experience  \\\n",
      "0    alice             new york           python, java           5   \n",
      "1      bob        san francisco  javascript, html, css           3   \n",
      "2  charlie               austin      python, java, sql           7   \n",
      "3    david              seattle              java, c++          10   \n",
      "4      eve               boston              python, r           2   \n",
      "\n",
      "   fit_category  \n",
      "0        No Fit  \n",
      "1      Best Fit  \n",
      "2  Moderate Fit  \n",
      "3      Best Fit  \n",
      "4      Best Fit  \n"
     ]
    }
   ],
   "source": [
    "# Let's assume we're clustering based on similarity scores\n",
    "def cluster_candidates(similarity_matrix, n_clusters=3):\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
    "    # Reshape similarity matrix to fit k-means input shape (candidate-job similarity)\n",
    "    kmeans.fit(similarity_matrix)\n",
    "    return kmeans.labels_\n",
    "\n",
    "# Cluster candidates into Best Fit, Moderate Fit, No Fit\n",
    "candidate_clusters = cluster_candidates(similarity_matrix)\n",
    "\n",
    "# Add the clusters to candidate dataframe\n",
    "df_candidates['fit_category'] = candidate_clusters\n",
    "\n",
    "# Map cluster labels to human-readable categories\n",
    "def map_cluster_to_fit_category(cluster_labels):\n",
    "    fit_categories = {0: 'Best Fit', 1: 'Moderate Fit', 2: 'No Fit'}\n",
    "    return [fit_categories[label] for label in cluster_labels]\n",
    "\n",
    "df_candidates['fit_category'] = map_cluster_to_fit_category(df_candidates['fit_category'])\n",
    "\n",
    "# Show the final candidates with their fit category\n",
    "print(\"Candidates with Fit Categories:\\n\", df_candidates)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a11e414-b700-4c09-a26a-a7ef9f56cc30",
   "metadata": {},
   "source": [
    "# Alternative Approach: Embeddings with Transformers (e.g., BERT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa621363-3b4d-4360-bbe8-cf01a5e7f9a4",
   "metadata": {},
   "source": [
    "### Step 1: Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9076c1e7-5857-4498-ac69-6145b6e651f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install transformers torch scikit-learn\n",
    "pip install huggingface_hub[hf_xet]\n",
    "pip install hf_xet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d6e610-29bb-47ad-990f-78ca5c1e49ba",
   "metadata": {},
   "source": [
    "### Step 2: Load BERT Model\n",
    "Weâ€™ll load a pre-trained BERT model from Hugging Face and use it to generate embeddings for the resumes and job descriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fb50ed9-36d7-4421-82e2-eb08365a7776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import re\n",
    "\n",
    "# Load the pre-trained BERT tokenizer and model from Hugging Face\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Check if GPU is available, otherwise fallback to CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa95a2f0-17bf-488c-b0ab-6c56a02a623d",
   "metadata": {},
   "source": [
    "### Step 3: Encode Text Using BERT\n",
    "We'll create a function that converts text into BERT embeddings. BERT returns embeddings for every token in the input, but we'll average these token embeddings to get a single vector representing the entire text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2019f853-bc59-4c03-8735-b950b26b4655",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to encode text using BERT and get the embeddings\n",
    "def get_bert_embedding(text):\n",
    "    # Tokenize the text and convert it to BERT's input format\n",
    "    inputs = tokenizer(text, return_tensors='pt', padding=True, truncation=True, max_length=512).to(device)\n",
    "    \n",
    "    # Pass the tokenized text through BERT\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    # Extract the last hidden state (token embeddings)\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    \n",
    "    # Take the mean of the token embeddings to get a single vector for the entire text\n",
    "    pooled_embedding = embeddings.mean(dim=1).squeeze()\n",
    "    \n",
    "    return pooled_embedding.cpu().numpy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae2d9dc-f45a-4230-a8e4-3602f28bc87d",
   "metadata": {},
   "source": [
    "### Step 4: Calculate Cosine Similarity\n",
    "Weâ€™ll use the cosine similarity to calculate how similar each candidateâ€™s resume is to the job description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e57aad24-302c-4383-b916-a8196befad58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Function to calculate cosine similarity between two vectors\n",
    "def calculate_cosine_similarity(embedding_1, embedding_2):\n",
    "    similarity = cosine_similarity([embedding_1], [embedding_2])\n",
    "    return similarity[0][0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce3a182b-ef67-4e8c-8f60-8f2cfcde705d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check for domain matching using regex\n",
    "def is_domain_matching(resume_text, domain_keywords):\n",
    "    \"\"\"\n",
    "    Check if any of the domain-related keywords match in the resume using regex.\n",
    "    \"\"\"\n",
    "    resume_text = resume_text.lower()\n",
    "    for keyword in domain_keywords:\n",
    "        # Check for a match of any domain-related keyword (case insensitive)\n",
    "        if re.search(r'\\b' + re.escape(keyword) + r'\\b', resume_text):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "# Function to evaluate candidates for each job description\n",
    "def evaluate_candidates_for_jobs(df_candidates, df_jobs, threshold_best=0.7, threshold_moderate=0.5):\n",
    "    job_candidates = {}\n",
    "\n",
    "    # Define the domain-related keywords for matching (can be extended based on your use case)\n",
    "    domain_keywords_map = {\n",
    "        'Software Engineering': ['software engineer', 'software engineering', 'software developer', 'developer', 'programmer'],\n",
    "        'Frontend Development': ['frontend developer', 'web developer', 'javascript', 'html', 'css'],\n",
    "        'Data Science': ['data scientist', 'machine learning', 'statistical analysis', 'data analysis'],\n",
    "        'Backend Development': ['backend developer', 'backend engineer', 'server-side', 'database'],\n",
    "        # Add more as needed...\n",
    "    }\n",
    "\n",
    "    # Process each job description\n",
    "    for _, job_row in df_jobs.iterrows():\n",
    "        job_desc_embedding = get_bert_embedding(job_row['description'])\n",
    "        \n",
    "        # List to store candidates for this job description\n",
    "        best_fit_candidates = []\n",
    "        moderate_fit_candidates = []\n",
    "\n",
    "        print(f\"\\nEvaluating job: {job_row['position_title']}\")\n",
    "\n",
    "        for _, resume_row in df_candidates.iterrows():\n",
    "            resume_embedding = get_bert_embedding(resume_row['resume_text'])\n",
    "            similarity_score = calculate_cosine_similarity(resume_embedding, job_desc_embedding)\n",
    "\n",
    "            # Check for domain match using domain keywords map\n",
    "            domain_keywords = domain_keywords_map.get(job_row['domain'], [])\n",
    "            if not is_domain_matching(resume_row['resume_text'], domain_keywords):\n",
    "                continue  # Exclude candidates who don't have experience in the job's domain\n",
    "\n",
    "            # Print cosine similarity scores for debugging\n",
    "            print(f\"Similarity between '{resume_row['name']}' and job '{job_row['position_title']}': {similarity_score:.4f}\")\n",
    "\n",
    "            # Classify based on similarity threshold\n",
    "            if similarity_score > threshold_best:\n",
    "                best_fit_candidates.append(resume_row['name'])\n",
    "            elif similarity_score > threshold_moderate:\n",
    "                moderate_fit_candidates.append(resume_row['name'])\n",
    "\n",
    "        # Combine best fit and moderate fit candidates into a final list\n",
    "        candidates_for_job = best_fit_candidates + moderate_fit_candidates\n",
    "\n",
    "        # Store the job and corresponding candidates' names (comma separated)\n",
    "        job_candidates[job_row['position_title']] = ', '.join(candidates_for_job) if candidates_for_job else \"No candidates\"\n",
    "\n",
    "    return job_candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d243e560-d4bd-4472-b7c0-5aae3dda2559",
   "metadata": {},
   "source": [
    "This will output the similarity score between the resume and the job description."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96ea3cd-fee8-428a-a881-d5bb85c43617",
   "metadata": {},
   "source": [
    "### Step 5: Classify Candidates Based on Similarity\n",
    "Now, letâ€™s extend the process to classify multiple candidates based on the similarity score. We can use a threshold-based classification as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1487141-624b-4105-95e8-874a5792f940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating job: Software Engineer\n",
      "Similarity between 'Alice' and job 'Software Engineer': 0.8755\n",
      "Similarity between 'Bob' and job 'Software Engineer': 0.7730\n",
      "Similarity between 'Charlie' and job 'Software Engineer': 0.8817\n",
      "Similarity between 'David' and job 'Software Engineer': 0.8266\n",
      "\n",
      "Evaluating job: Frontend Developer\n",
      "Similarity between 'Bob' and job 'Frontend Developer': 0.9222\n",
      "\n",
      "Evaluating job: Senior Software Engineer\n",
      "Similarity between 'Alice' and job 'Senior Software Engineer': 0.8767\n",
      "Similarity between 'Bob' and job 'Senior Software Engineer': 0.8111\n",
      "Similarity between 'Charlie' and job 'Senior Software Engineer': 0.9162\n",
      "Similarity between 'David' and job 'Senior Software Engineer': 0.8558\n",
      "\n",
      "Evaluating job: Lead Developer\n",
      "Similarity between 'Alice' and job 'Lead Developer': 0.9081\n",
      "Similarity between 'Bob' and job 'Lead Developer': 0.8986\n",
      "Similarity between 'Charlie' and job 'Lead Developer': 0.9258\n",
      "Similarity between 'David' and job 'Lead Developer': 0.9584\n",
      "\n",
      "Evaluating job: Data Scientist\n",
      "Similarity between 'Alice' and job 'Data Scientist': 0.8665\n",
      "Similarity between 'Eve' and job 'Data Scientist': 0.9249\n",
      "\n",
      "Final Results:\n",
      "Software Engineer: Alice, Bob, Charlie, David\n",
      "Frontend Developer: Bob\n",
      "Senior Software Engineer: Alice, Bob, Charlie, David\n",
      "Lead Developer: Alice, Bob, Charlie, David\n",
      "Data Scientist: Alice, Eve\n"
     ]
    }
   ],
   "source": [
    "# Sample Candidate Data (Source 1)\n",
    "df_candidates = pd.DataFrame({\n",
    "    'name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
    "    'location_preferences': ['New York', 'San Francisco', 'Austin', 'Seattle', 'Boston'],\n",
    "    'languages_known': ['Python, Java', 'JavaScript, HTML, CSS', 'Python, Java, SQL', 'Java, C++', 'Python, R'],\n",
    "    'experience': [5, 3, 7, 10, 2]\n",
    "})\n",
    "\n",
    "# Add the resume text column\n",
    "df_candidates['resume_text'] = [\n",
    "    \"Experienced software engineer with a strong background in Python, Java. Worked on large-scale applications in AI and data analysis.\",\n",
    "    \"Frontend developer with experience in building responsive web applications using JavaScript, HTML, and CSS.\",\n",
    "    \"Senior software engineer with experience in backend development using Python, Java. Strong experience with databases and data processing.\",\n",
    "    \"Lead developer with expertise in Java and C++. Managed a team of engineers in building scalable systems.\",\n",
    "    \"Junior data scientist skilled in Python, R, machine learning, and statistical analysis.\"\n",
    "]\n",
    "\n",
    "# Sample Job Description Data (Source 3)\n",
    "df_jobs = pd.DataFrame({\n",
    "    'position_title': ['Software Engineer', 'Frontend Developer', 'Senior Software Engineer', 'Lead Developer', 'Data Scientist'],\n",
    "    'description': [\n",
    "        \"We are looking for a software engineer with experience in Python and Java. Should have a good understanding of algorithms and problem-solving.\",\n",
    "        \"Frontend developer needed for web application development. Proficiency in JavaScript, HTML, and CSS is required.\",\n",
    "        \"Senior software engineer required with experience in backend technologies like Python, Java. Knowledge of databases is necessary.\",\n",
    "        \"Lead developer with experience in Java and C++, experience in managing teams and building scalable systems.\",\n",
    "        \"Data scientist role for someone skilled in Python, R, machine learning, and statistical analysis. Experience with data manipulation is a plus.\"\n",
    "    ],\n",
    "    'experience_required': [4, 2, 6, 8, 3],\n",
    "    'domain': ['Software Engineering', 'Frontend Development', 'Software Engineering', 'Software Engineering', 'Data Science'],\n",
    "    'location': ['New York', 'San Francisco', 'Austin', 'Seattle', 'Boston']\n",
    "})\n",
    "\n",
    "# Final Results:\n",
    "# Software Engineer: Alice, Bob, Charlie, David\n",
    "# Frontend Developer: Bob\n",
    "# Senior Software Engineer: Alice, Bob, Charlie, David\n",
    "# Lead Developer: Alice, Bob, Charlie, David\n",
    "# Data Scientist: Alice, Eve\n",
    "\n",
    "# Run the evaluation\n",
    "job_candidates = evaluate_candidates_for_jobs(df_candidates, df_jobs)\n",
    "\n",
    "# Print the final output (Job Description and Candidates)\n",
    "print(\"\\nFinal Results:\")\n",
    "for job, candidates in job_candidates.items():\n",
    "    print(f\"{job}: {candidates}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
