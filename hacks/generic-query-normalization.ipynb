{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189e79cc-1c7f-40fb-a913-89b25261f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install spacy nltk\n",
    "python -m spacy download en_core_web_sm\n",
    "\n",
    "python -c \"import nltk; nltk.download('stopwords')\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bb25e18-4f70-44c3-ba96-2b33def06fd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Give me top 10 retailers \n",
      "Normalized Key: ('f3a71e3238cac77be6040ad8267f8630', 'get_retailer_top')\n",
      "\n",
      "Original: show me top 10 retailers \n",
      "Normalized Key: ('f3a71e3238cac77be6040ad8267f8630', 'get_retailer_top')\n",
      "\n",
      "Original: list top 10 retailers \n",
      "Normalized Key: ('f3a71e3238cac77be6040ad8267f8630', 'get_retailer_top')\n",
      "\n",
      "Original: who are the 10 retailers selling more \n",
      "Normalized Key: ('f3a71e3238cac77be6040ad8267f8630', 'get_retailer_top')\n",
      "\n",
      "Original: 10 retailers in top list \n",
      "Normalized Key: ('f3a71e3238cac77be6040ad8267f8630', 'get_retailer_top')\n",
      "\n",
      "Original: ten retailers performing well \n",
      "Normalized Key: ('100ff4454fff20c53112c4195d8aa809', 'retailer_top')\n",
      "\n",
      "Original: best 10 sellers in the market \n",
      "Normalized Key: ('7c155639f72671438f9ed7a7878bd0ce', 'market_seller_top')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# Load English NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Synonym mapping (extendable)\n",
    "synonym_map = {\n",
    "    \"show\": \"get\",\n",
    "    \"list\": \"get\",\n",
    "    \"who are\": \"get\",\n",
    "    \"selling more\": \"top\",\n",
    "    \"performing well\": \"top\",\n",
    "    \"ten\": \"10\",\n",
    "    \"best\": \"top\",\n",
    "    \"give\": \"get\"\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def normalize_query(user_query):\n",
    "    \"\"\"Normalize user queries to generate a unique cache key.\"\"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    query = user_query.lower()\n",
    "    \n",
    "    # Apply synonym mapping\n",
    "    for key, value in synonym_map.items():\n",
    "        query = query.replace(key, value)\n",
    "\n",
    "    # Remove special characters and extra spaces\n",
    "    query = re.sub(r\"[^\\w\\s]\", \"\", query).strip()\n",
    "\n",
    "    # Tokenize and lemmatize\n",
    "    doc = nlp(query)\n",
    "    keywords = [token.lemma_ for token in doc if token.text not in stop_words and token.is_alpha]\n",
    "\n",
    "    # Sort keywords to maintain consistency\n",
    "    normalized = \"_\".join(sorted(set(keywords)))\n",
    "\n",
    "    # Generate a unique cache key (hashing ensures consistent lookup)\n",
    "    cache_key = hashlib.md5(normalized.encode()).hexdigest()\n",
    "\n",
    "    return cache_key, normalized\n",
    "\n",
    "# Example Queries\n",
    "queries = [\n",
    "    \"Give me top 10 retailers\",\n",
    "    \"show me top 10 retailers\",\n",
    "    \"list top 10 retailers\",\n",
    "    \"who are the 10 retailers selling more\",\n",
    "    \"10 retailers in top list\",\n",
    "    \"ten retailers performing well\",\n",
    "    \"best 10 sellers in the market\"\n",
    "]\n",
    "\n",
    "# Normalize all queries\n",
    "for q in queries:\n",
    "    print(f\"Original: {q} \\nNormalized Key: {normalize_query(q)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88a9e907-04c8-4088-a4f3-16633287ef08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Give me top 10 retailers \n",
      "Normalized Key: ('f6203084ae20217a004ab068b08b25aa', '10_give_retailer_top')\n",
      "\n",
      "Original: show me top 10 retailers \n",
      "Normalized Key: ('da6fa66d4c05a94c79031eca0439ed24', '10_get_retailer_top')\n",
      "\n",
      "Original: list top 10 retailers \n",
      "Normalized Key: ('da6fa66d4c05a94c79031eca0439ed24', '10_get_retailer_top')\n",
      "\n",
      "Original: who are the 10 retailers selling more \n",
      "Normalized Key: ('da6fa66d4c05a94c79031eca0439ed24', '10_get_retailer_top')\n",
      "\n",
      "Original: 10 retailers in top list \n",
      "Normalized Key: ('da6fa66d4c05a94c79031eca0439ed24', '10_get_retailer_top')\n",
      "\n",
      "Original: ten retailers performing well \n",
      "Normalized Key: ('dcc1d7d8a4e2cedb43d11b51447369bf', '10_retailer_top')\n",
      "\n",
      "Original: best 5 sellers in the market \n",
      "Normalized Key: ('6ad3bd4943ed3bf4f02496b04d694cee', '5_market_seller_top')\n",
      "\n",
      "Original: show top 20 products \n",
      "Normalized Key: ('7e32b3d15c33c850202a3e46176e0eba', '20_get_product_top')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "# Load English NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Synonym mapping (extendable)\n",
    "synonym_map = {\n",
    "    \"show\": \"get\",\n",
    "    \"list\": \"get\",\n",
    "    \"who are\": \"get\",\n",
    "    \"selling more\": \"top\",\n",
    "    \"performing well\": \"top\",\n",
    "    \"ten\": \"10\",\n",
    "    \"best\": \"top\",\n",
    "}\n",
    "\n",
    "def normalize_query(user_query):\n",
    "    \"\"\"Normalize user queries while keeping numerics for caching.\"\"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    query = user_query.lower()\n",
    "    \n",
    "    # Apply synonym mapping\n",
    "    for key, value in synonym_map.items():\n",
    "        query = query.replace(key, value)\n",
    "\n",
    "    # Extract numbers separately\n",
    "    numbers = re.findall(r'\\d+', query)  # Finds all numeric values\n",
    "    \n",
    "    # Remove special characters except numbers\n",
    "    query = re.sub(r\"[^\\w\\s]\", \"\", query).strip()\n",
    "\n",
    "    # Tokenize and lemmatize\n",
    "    doc = nlp(query)\n",
    "    keywords = [token.lemma_ for token in doc if token.text not in stop_words and (token.is_alpha or token.is_digit)]\n",
    "\n",
    "    # Combine keywords and numbers\n",
    "    keywords += numbers  # Ensure numbers are included in the key\n",
    "\n",
    "    # Sort keywords to maintain consistency\n",
    "    normalized = \"_\".join(sorted(set(keywords)))\n",
    "\n",
    "    # Generate a unique cache key (hashing ensures consistent lookup)\n",
    "    cache_key = hashlib.md5(normalized.encode()).hexdigest()\n",
    "\n",
    "    return cache_key, normalized\n",
    "\n",
    "# Example Queries\n",
    "queries = [\n",
    "    \"Give me top 10 retailers\",\n",
    "    \"show me top 10 retailers\",\n",
    "    \"list top 10 retailers\",\n",
    "    \"who are the 10 retailers selling more\",\n",
    "    \"10 retailers in top list\",\n",
    "    \"ten retailers performing well\",\n",
    "    \"best 5 sellers in the market\",\n",
    "    \"show top 20 products\",\n",
    "]\n",
    "\n",
    "# Normalize all queries\n",
    "for q in queries:\n",
    "    print(f\"Original: {q} \\nNormalized Key: {normalize_query(q)}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "729a410b-88a3-47ec-ba7d-9aa8c9798241",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: Give me top 10 retailers \n",
      "Normalized Query: give top 10 retailer\n",
      "\n",
      "Original: show me top 10 retailers \n",
      "Normalized Query: give top 10 retailer\n",
      "\n",
      "Original: list top 10 retailers \n",
      "Normalized Query: give top 10 retailer\n",
      "\n",
      "Original: who are the 10 retailers selling more \n",
      "Normalized Query: give 10 retailer top\n",
      "\n",
      "Original: 10 retailers in top list \n",
      "Normalized Query: 10 retailer top give\n",
      "\n",
      "Original: ten retailers performing well \n",
      "Normalized Query: 10 retailer top\n",
      "\n",
      "Original: best 5 sellers in the market \n",
      "Normalized Query: top 5 seller market\n",
      "\n",
      "Original: show top 20 products \n",
      "Normalized Query: give top 20 product\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "import hashlib\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Load NLP model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "\n",
    "# Synonym mapping (extendable)\n",
    "synonym_map = {\n",
    "    \"show\": \"give\",\n",
    "    \"list\": \"give\",\n",
    "    \"who are\": \"give\",\n",
    "    \"selling more\": \"top\",\n",
    "    \"performing well\": \"top\",\n",
    "    \"ten\": \"10\",\n",
    "    \"best\": \"top\",\n",
    "}\n",
    "\n",
    "def normalize_query(user_query):\n",
    "    \"\"\"Normalize user queries while preserving order for LLM SQL generation.\"\"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    query = user_query.lower()\n",
    "\n",
    "    # Apply synonym mapping\n",
    "    for key, value in synonym_map.items():\n",
    "        query = query.replace(key, value)\n",
    "\n",
    "    # Extract numbers separately\n",
    "    numbers = re.findall(r'\\d+', query)  # Finds all numeric values\n",
    "\n",
    "    # Tokenize and lemmatize\n",
    "    doc = nlp(query)\n",
    "    keywords = [\n",
    "        token.lemma_ for token in doc \n",
    "        if token.text not in stop_words or token.text in [\"give\", \"top\"]  # Keep essential words\n",
    "    ]\n",
    "\n",
    "    # Merge back numbers in the same position\n",
    "    final_query = []\n",
    "    num_index = 0\n",
    "\n",
    "    for word in keywords:\n",
    "        if word.isdigit():\n",
    "            final_query.append(numbers[num_index])  # Keep original numeric position\n",
    "            num_index += 1\n",
    "        else:\n",
    "            final_query.append(word)\n",
    "\n",
    "    # Join words in proper order\n",
    "    normalized = \" \".join(final_query)\n",
    "\n",
    "    # Generate a unique cache key\n",
    "    cache_key = hashlib.md5(normalized.encode()).hexdigest()\n",
    "\n",
    "    return cache_key, normalized\n",
    "\n",
    "# Example Queries\n",
    "queries = [\n",
    "    \"Give me top 10 retailers\",\n",
    "    \"show me top 10 retailers\",\n",
    "    \"list top 10 retailers\",\n",
    "    \"who are the 10 retailers selling more\",\n",
    "    \"10 retailers in top list\",\n",
    "    \"ten retailers performing well\",\n",
    "    \"best 5 sellers in the market\",\n",
    "    \"show top 20 products\",\n",
    "]\n",
    "\n",
    "# Normalize all queries\n",
    "for q in queries:\n",
    "    print(f\"Original: {q} \\nNormalized Query: {normalize_query(q)[1]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3b7e00-e657-4fbf-a5d4-5ab07fda93d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
